{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/gabrielrucker/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/gabrielrucker/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/gabrielrucker/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     /home/gabrielrucker/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from nltk import tokenize\n",
    "from string import punctuation\n",
    "from string import ascii_letters\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn import metrics\n",
    "from pandas_ods_reader import read_ods\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from pylab import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
    "from matplotlib import pyplot as plt\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para ler os dados e realizar algumas definições\n",
    "#Entrada: Nenhuma\n",
    "#Saída: Dataframe com os dados e os tipos atribuídos\n",
    "\n",
    "def leitura_e_configuracao():\n",
    "    df = read_ods(\"base-de-dados-cientificos.ods\",1)\n",
    "\n",
    "    #Define os tipos de dados das colunas\n",
    "    df['Palavras-chave'] = df['Palavras-chave'].astype(str)\n",
    "    df['Título'] = df['Título'].astype(str)\n",
    "    df['Resumo'] = df['Resumo'].astype(str)\n",
    "    df['Categoria'] = df['Categoria'].astype(str)\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    \n",
    "    # atribuição dos ids a cada uma das categorias\n",
    "    for abstract in df:\n",
    "        df.loc[df['Categoria'] == 'Ciências Agrárias', 'ID_Categoria'] = 0\n",
    "        df.loc[df['Categoria'] == 'Ciências Biológicas', 'ID_Categoria'] = 1\n",
    "        df.loc[df['Categoria'] == 'Ciências Exatas e da Terra', 'ID_Categoria'] = 2\n",
    "        df.loc[df['Categoria'] == 'Ciências Humanas', 'ID_Categoria'] = 3\n",
    "        df.loc[df['Categoria'] == 'Ciências Sociais Aplicadas', 'ID_Categoria'] = 4\n",
    "        df.loc[df['Categoria'] == 'Ciências da Saúde', 'ID_Categoria'] = 5\n",
    "        df.loc[df['Categoria'] == 'Engenharias', 'ID_Categoria'] = 6\n",
    "        df.loc[df['Categoria'] == 'Lingüística, Letras e Artes', 'ID_Categoria'] = 7\n",
    "        df.loc[df['Categoria'] == 'Multidisciplinar', 'ID_Categoria'] = 8\n",
    "    \n",
    "    df['ID_Categoria'] = df['ID_Categoria'].astype(int) #tipo de dado da nova coluna criada\n",
    "    df['Texto'] = df['Título'] + df['Resumo'] + df['Palavras-chave'] # Atributo texto é a união do título, resumo\n",
    "                                                                     # e palavras-chave\n",
    "    \n",
    "    return df # retorna o dataframe\n",
    "    \n",
    "#Função para realizar o pré-processamento dos dados\n",
    "#Entrada: Dataframe com os dados e o atributo a ser pré-processado\n",
    "#Saída: Nenhuma\n",
    "\n",
    "def pre_processamento(df, atributo):\n",
    "    \n",
    "    #letras minúsculas\n",
    "    df[atributo] = [texto.lower() for texto in df[atributo]]\n",
    "\n",
    "    #remoção de acentos\n",
    "    df[atributo] = [unidecode.unidecode(texto) for texto in df[atributo]]\n",
    "\n",
    "    #remoção de stop words\n",
    "    stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "    stop_words.extend(['artigo','sobre', 'resultado','objetivo','estudo','brasil', 'trabalho', \n",
    "                      'delineamento', 'experimental','analise'])\n",
    "    lista_stopwords = []\n",
    "    for abstract in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(abstract)\n",
    "        novo_texto = ' '.join([token for token in tokens if token not in stop_words])\n",
    "        lista_stopwords.append(novo_texto)\n",
    "    df[atributo] = lista_stopwords\n",
    "\n",
    "    #remoção de pontuação\n",
    "    pontuacoes = list(punctuation)\n",
    "    pontuacao = []\n",
    "    for texto in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(texto)\n",
    "        novo_texto = ' '.join([token for token in tokens if token not in pontuacoes])\n",
    "        pontuacao.append(novo_texto)\n",
    "    df[atributo] = pontuacao\n",
    "\n",
    "    #Retira textos não desejados\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'[0-9]','',x))\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'[/(){}\\[\\]\\#\\|@,;.:-]',' ',x))\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "    #obtenção da raíz das palavras\n",
    "    stemmer = RSLPStemmer()\n",
    "    raizes = []\n",
    "    for texto in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(texto)\n",
    "        novo_texto = ' '.join([stemmer.stem(token) for token in tokens])\n",
    "        raizes.append(novo_texto)\n",
    "    df[atributo] = raizes\n",
    "    \n",
    "\n",
    "def extracao_caracteristicas(df, atributo):\n",
    "    # aplicação do TF-IDF para extração de características\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, 2))\n",
    "    vetor_caracteristicas = tfidf.fit_transform(df[atributo]).toarray()\n",
    "    rotulos = df.ID_Categoria\n",
    "    return vetor_caracteristicas, rotulos\n",
    "\n",
    "def selecao_caracteristicas(vetor_caracteristicas, rotulos):\n",
    "    chi2_test = SelectKBest(chi2,k=int((vetor_caracteristicas.shape[1]/2)))\n",
    "    vetor_caracteristicas = chi2_test.fit_transform(vetor_caracteristicas,rotulos)\n",
    "    return vetor_caracteristicas\n",
    "\n",
    "def classificacao(df, modelo, vetor_caracteristicas, rotulos):\n",
    "    \n",
    "    ### cross-validation ###\n",
    "    \n",
    "    vc_df = pd.DataFrame(index=range(10))\n",
    "    entradas = []\n",
    "    acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "    for num_fold, acuracia in enumerate(acuracias):\n",
    "        entradas.append((num_fold, acuracia))\n",
    "    vc_df = pd.DataFrame(entradas, columns=['num_fold', 'acuracia'])\n",
    "    \n",
    "    return vc_df.acuracia.mean() # média das acurácias\n",
    "\n",
    "def cria_grafico(dimensao, atributo, classificador):\n",
    "    ruidos = [0, 10, 20, 30, 40]\n",
    "    acuracias = []\n",
    "    for ruido in ruidos:\n",
    "        df = leitura_e_configuracao()\n",
    "        if(dimensao == 'Acurácia-add'):\n",
    "            contamina_acuracia(df, atributo, 'adicao', ruido)\n",
    "        elif(dimensao == 'Acurácia-rm'):\n",
    "            contamina_acuracia(df, atributo, 'remocao', ruido)\n",
    "        elif(dimensao == 'Acurácia-subs'):\n",
    "            contamina_acuracia(df, atributo, 'substituicao', ruido)\n",
    "        elif(dimensao == 'Completude'):\n",
    "            contamina_completude(df, atributo, ruido)\n",
    "        elif(dimensao == 'Consistência'):\n",
    "            contamina_consistencia(df, atributo, ruido)\n",
    "        pre_processamento(df, atributo)\n",
    "        vetor_caracteristicas, rotulos = extracao_caracteristicas(df, atributo)\n",
    "        vetor_caracteristicas = selecao_caracteristicas(vetor_caracteristicas, rotulos)\n",
    "        acuracia = classificacao(df, classificador, vetor_caracteristicas, rotulos)\n",
    "        acuracias.append(acuracia)\n",
    "    plt.show()\n",
    "    \n",
    "    return acuracias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_lista_valores(string):\n",
    "    lista_valores = []\n",
    "    lista_carac = []\n",
    "    i = 0\n",
    "    for i in range(len(string)):\n",
    "        lista_carac.append(string[i])\n",
    "    return [int(ord(carac)) for carac in lista_carac]\n",
    "\n",
    "def calcula_media(lista_valores):\n",
    "    soma = 0\n",
    "    media = 0\n",
    "    for valor in lista_valores:\n",
    "        soma += valor\n",
    "    return soma / len(lista_valores)\n",
    "\n",
    "def calcula_desvio(lista_valores, media):\n",
    "    desvio = 0\n",
    "    for valor in lista_valores:\n",
    "        desvio += (valor - media)**2\n",
    "    return (desvio / len(lista_valores))**(1/2)\n",
    "\n",
    "def ruido_gaussiano(media, desvio, valor):\n",
    "    return (1 / (desvio * math.sqrt(2 * math.pi))) * math.exp(-(((valor - media) ** 2) / (2 * (desvio ** 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def contamina_acuracia(df, escolha_atributo, metodo, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    \n",
    "    if (porc_ruido == 0): # retorna caso não haja contaminação\n",
    "        return\n",
    "    \n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100)) # quantidade de artigos que serão contaminados\n",
    "    atributo_contaminado = escolha_atributo \n",
    "    i = 0\n",
    "    \n",
    "    while i < qtd_artigos: # laço para contaminar os artigos\n",
    "        \n",
    "        lista_carac = []\n",
    "        lista_valores = []\n",
    "        indice = random.choice(df.index) # artigo é selecionado de maneira aleatória\n",
    "        \n",
    "        if indice in lista_artigos: # verifica se o artigo já foi contaminado previamente\n",
    "            while indice in lista_artigos:\n",
    "                indice = random.choice(df.index)\n",
    "                \n",
    "        lista_valores = gera_lista_valores(df.loc[indice, atributo_contaminado]) # obtém os valores em ascii \n",
    "                                                                                 # em formato de lista\n",
    "        media = calcula_media(lista_valores) # cálculo da média dos valores em ascii\n",
    "        desvio = calcula_desvio(lista_valores, media) # desvio padrão dos valores em ascii\n",
    "        \n",
    "        for valor in lista_valores: # percorre os caracteres em ascii\n",
    "            \n",
    "            if (((0.607 / (math.sqrt(2*math.pi)*desvio)) <= ruido_gaussiano(media,desvio,valor) <= 1) \n",
    "                and (chr(valor).isalpha())): # se o caracter for contaminado\n",
    "                \n",
    "                caracter = random.choice(ascii_letters) # obtém um caracter aleatório\n",
    "                \n",
    "                if(not caracter.isalpha()): # gera novo caracter enquanto este não for alfabético\n",
    "                    while(not caracter.isalpha()):\n",
    "                        caracter = random.choice(ascii_letters)\n",
    "                                \n",
    "                if(metodo == 'substituicao'): # método de substituição de caracteres\n",
    "                    lista_carac.append(caracter) # adiciona o caracter aleatório no lugar do antigo na nova lista\n",
    "                elif(metodo == 'adicao'): # método de adição de caracteres\n",
    "                    lista_carac.extend([chr(valor), caracter]) # adiciona o caracter antigo junto com o aleatório\n",
    "                                                               # à nova lista\n",
    "                elif(metodo == 'remocao'): # remoção de caracteres\n",
    "                    pass # caso o caracter seja contaminado, ele não é adicionado à lista de caracteres\n",
    "            \n",
    "            else: # caracter não será contaminado\n",
    "                lista_carac.append(chr(valor)) # troca o valor em ascii pelo caracter correspondente\n",
    "                                               # e o adiciona à lista\n",
    "                \n",
    "        df.loc[indice, atributo_contaminado] = ''.join([carac for carac in lista_carac]) # substitui o artigo pela\n",
    "                                                                                         # lista resultante\n",
    "        lista_artigos.append(indice) # adiciona o índice do artigo à lista de artigos contaminados\n",
    "        i+=1\n",
    "\n",
    "def contamina_completude(df, escolha_atributo, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    #lista_atributos = ['Título', 'Resumo', 'Palavras-chave']\n",
    "    if(porc_ruido == 0):\n",
    "        return\n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100))\n",
    "    i = 0\n",
    "    atributo_contaminado = escolha_atributo\n",
    "    while i < qtd_artigos:\n",
    "        indice = random.choice(df.index) # sorteia um artigo aleatório\n",
    "        if indice in lista_artigos: # se o artigo já foi contaminado\n",
    "            while indice in lista_artigos: # procura por um novo artigo enquanto estiver na lista dos que já foram contaminados\n",
    "                indice = random.choice(df.index)\n",
    "        df[atributo_contaminado] = df[atributo_contaminado].replace([df[atributo_contaminado][indice]], '') # apaga o atributo\n",
    "        lista_artigos.append(indice) # adiciona o artigo contaminado à lista de artigos que já foram contaminados\n",
    "        i += 1\n",
    "        \n",
    "def contamina_consistencia(df, escolha_atributo1, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    lista_atributos = ['Título', 'Resumo', 'Palavras-chave']\n",
    "    if(porc_ruido == 0):\n",
    "        return\n",
    "    porc_ruido /= 2\n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100)) # número de artigos a serem contaminados\n",
    "    i = 0\n",
    "    atributo_contaminado1 = escolha_atributo1\n",
    "    atributo_contaminado2 = random.choice(lista_atributos)\n",
    "    while i < qtd_artigos:\n",
    "        indice1 = random.choice(df.index)\n",
    "        indice2 = random.choice(df.index)\n",
    "        if(df['ID_Categoria'][indice1] == df['ID_Categoria'][indice2]):\n",
    "                while(df['ID_Categoria'][indice1] == df['ID_Categoria'][indice2]):\n",
    "                        indice1 = random.choice(df.index)\n",
    "        \n",
    "        else:\n",
    "            temp = df[atributo_contaminado1][indice1]\n",
    "            if(atributo_contaminado2 == atributo_contaminado1):\n",
    "                while(atributo_contaminado2 == atributo_contaminado1):\n",
    "                    atributo_contaminado2 = random.choice(lista_atributos)\n",
    "            df[atributo_contaminado1] = df[atributo_contaminado1].replace([df[atributo_contaminado1][indice1]], [df[atributo_contaminado2][indice2]])\n",
    "            df[atributo_contaminado2] = df[atributo_contaminado2].replace([df[atributo_contaminado2][indice2]], temp)\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def melhor_divisao(modelo):\n",
    "    lista_acuracias = []\n",
    "    lista_porc = []\n",
    "    i = 0.01\n",
    "    while i < 1:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=i, random_state=0)\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        lista_acuracias.append(accuracy_score(y_test, y_pred)*100)\n",
    "        lista_porc.append(i*100)\n",
    "        i += 0.01\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lista_porc, lista_acuracias, 'black')\n",
    "    plt.xlabel('Conjunto de Treino (%)')\n",
    "    plt.ylabel('Acurácia (%)')\n",
    "    indice = lista_acuracias.index(max(lista_acuracias))\n",
    "    plt.scatter(lista_porc[indice], max(lista_acuracias), c='red', linewidths=2)\n",
    "    plt.axhline(y=max(lista_acuracias), xmax=lista_porc[indice]/105, linestyle='--', color=\"red\")\n",
    "    plt.axvline(x=lista_porc[indice], ymax=max(lista_acuracias)/(max(lista_acuracias)+5), linestyle='--', color=\"red\")\n",
    "    plt.text(lista_porc[indice]+2, max(lista_acuracias)+0.5, '({:.1f}, {:.1f})'.format(lista_porc[indice], max(lista_acuracias)))\n",
    "    plt.margins(0.1)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    #font = {'family':'sans-serif',\n",
    "    #        'weight':'normal',\n",
    "    #        'size': 16}\n",
    "    #plt.rc('font', **font)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gera_curvas_roc(modelo, cjto_treino):\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=(cjto_treino/100), random_state=0)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    pred_prob = modelo.predict_proba(X_test)\n",
    "    \n",
    "    FPR = {}\n",
    "    TPR = {}\n",
    "    limite = {}\n",
    "\n",
    "    num_classes = 9\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        FPR[i], TPR[i], limite[i] = roc_curve(y_test, pred_prob[:, i], pos_label=i)  \n",
    "    \n",
    "    # plotando a área sob a curva\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(FPR[0], TPR[0], color='#e41a1c', linestyle='-', label='CA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[1], TPR[1], color='#377eb8', linestyle='-', label='CB vs Resto',linewidth=3)\n",
    "    plt.plot(FPR[2], TPR[2], color='#4daf4a', linestyle='-', label='CET vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[3], TPR[3], color='#984ea3', linestyle='-', label='CH vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[4], TPR[4], color='#ff7f00', linestyle='-', label='CSA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[5], TPR[5], color='#ffff33', linestyle='-', label='CS vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[6], TPR[6], color='#a65628', linestyle='-', label='E vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[7], TPR[7], color='#f781bf', linestyle='-', label='LLA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[8], TPR[8], color='#999999', linestyle='-', label='M vs Resto', linewidth=3)\n",
    "    plt.xlabel('Taxa de Falsos Positivos (1 - Especificidade)', weight='book')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)', weight='book')\n",
    "    ax.xaxis.set_tick_params(width=2)\n",
    "    ax.yaxis.set_tick_params(width=2)\n",
    "    leg = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=26, shadow=True,\n",
    "                     fancybox=True)\n",
    "    leg.get_frame().set_linewidth(3)\n",
    "    for i in range(num_classes):\n",
    "        leg.get_lines()[i].set_linewidth(5)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.setp(ax.spines.values(), linewidth=2)\n",
    "    fig.set_size_inches(20, 10)\n",
    "    \n",
    "    font = {'family':'sans-serif',\n",
    "            'weight':'book',\n",
    "            'size': 26}\n",
    "    plt.rc('font', **font)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_box_plot(eixo_x, eixo_y, dados):\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    flierprops = dict(marker='*', markerfacecolor='black', markersize=8,\n",
    "                  markeredgecolor='none')\n",
    "    medianprops = dict(linestyle='-', linewidth=1.1)\n",
    "\n",
    "    sns.boxplot(x=eixo_x, y=eixo_y, palette='bright', data=dados, orient='v', width=0.3,\n",
    "           saturation=1, linewidth=1, showcaps=False, flierprops=flierprops, medianprops=medianprops)\n",
    "    #sns.stripplot(x='Acurácia (%)', y='Classificador', data=vc_df, \n",
    "              #size=10, jitter=0.3, edgecolor=\"gray\", linewidth=1, palette='pastel')\n",
    "\n",
    "    #plt.xticks(\n",
    "    #    rotation=45, \n",
    "    #    horizontalalignment='right',\n",
    "    #    fontweight='light',\n",
    "    #    fontsize='medium'  \n",
    "    #)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes-Contaminação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "atributo = 'Texto'\n",
    "metodos = ['Acurácia-add','Completude','Consistência']\n",
    "modelo = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "for metodo in metodos:\n",
    "    arquivo = open(\"lr-novo/{}-{}.txt\".format(atributo,metodo),\"w\")\n",
    "    i=0\n",
    "    for i in range(10):\n",
    "        lista_acuracias = cria_grafico(metodo, atributo, modelo)\n",
    "        for acuracia in lista_acuracias:\n",
    "            arquivo.write(\"{} \\t\".format(acuracia))    \n",
    "        arquivo.write(\"\\n\\n\")\n",
    "    arquivo.close()\n",
    "    print(\"{}: {} ✔\\n\".format(atributo, metodo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-processamento/Extração/Seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = leitura_e_configuracao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_processamento(df, 'Texto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_caracteristicas, rotulos = extracao_caracteristicas(df, 'Texto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_caracteristicas = selecao_caracteristicas(vetor_caracteristicas, rotulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, solver='liblinear')\n",
    "]\n",
    "    \n",
    "vc_df = pd.DataFrame(index=range(10 * len(modelos)))\n",
    "\n",
    "entradas = []\n",
    "\n",
    "for modelo in modelos:\n",
    "    nome_modelo = modelo.__class__.__name__\n",
    "    if(nome_modelo == \"LinearSVC\"):\n",
    "        nome_modelo = \"MVS\"\n",
    "    elif(nome_modelo == \"MultinomialNB\"):\n",
    "        nome_modelo = \"NB\"\n",
    "    elif(nome_modelo == \"LogisticRegression\"):\n",
    "        nome_modelo = \"RL\"\n",
    "    acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "    for num_fold, acuracia in enumerate(acuracias):\n",
    "        entradas.append((nome_modelo, num_fold, acuracia))\n",
    "        \n",
    "vc_df = pd.DataFrame(entradas, columns=['Classificador', 'Num_Fold', 'Acurácia (%)'])\n",
    "vc_df['Acurácia (%)'] = [acuracia * 100 for acuracia in vc_df['Acurácia (%)']]\n",
    "    \n",
    "cria_box_plot('Classificador', 'Acurácia (%)', vc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vc_df['Acurácia'] = vc_df['Acurácia (%)']\n",
    "acuracias = vc_df.groupby('Classificador').Acurácia.mean()\n",
    "acuracias.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acuracias_desvios = vc_df.groupby('Classificador').Acurácia.std()\n",
    "acuracias_desvios.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "modelo = MultinomialNB()\n",
    "acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "print(mean(acuracias)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loo = LeaveOneOut()\n",
    "modelo = LogisticRegression(random_state=0, solver='liblinear')\n",
    "acuracia = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=loo)\n",
    "print(mean(acuracia)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divisão treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melhor_divisao(LinearSVC(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=0.63, random_state=0)\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo = SVC(kernel=\"linear\", probability=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=0.63, random_state=0)\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "#criação de dicionário (categoria,id)\n",
    "category_id_df = df[['Categoria', 'ID_Categoria']].drop_duplicates().sort_values('ID_Categoria')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "#criação de dicionário (id, categoria)\n",
    "id_to_category = dict(category_id_df[['ID_Categoria', 'Categoria']].values)\n",
    "\n",
    "#criação das siglas\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Agrárias', 'Categoria'] = 'CA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Biológicas', 'Categoria'] = 'CB'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Exatas e da Terra', 'Categoria'] = 'CET'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Humanas', 'Categoria'] = 'CH'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Sociais Aplicadas', 'Categoria'] = 'CSA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências da Saúde', 'Categoria'] = 'CS'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Engenharias', 'Categoria'] = 'E'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Lingüística, Letras e Artes', 'Categoria'] = 'LLA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Multidisciplinar', 'Categoria'] = 'M'\n",
    "\n",
    "#matriz de confusão\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "conf_mat.diagonal()/conf_mat.sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "xticklabels=category_id_df.Categoria.values, yticklabels=category_id_df.Categoria.values)\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imprime as métricas\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=df['Categoria'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curvas-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "modelo_calibrado = CalibratedClassifierCV(LinearSVC(random_state=0), cv=10, ensemble=False)\n",
    "\n",
    "gera_curvas_roc(modelo_calibrado, 63)\n",
    "gera_curvas_roc(MultinomialNB(), 82)\n",
    "gera_curvas_roc(LogisticRegression(random_state=0, solver='liblinear'), 82)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = read_ods(\"resultados-folds-formatado.ods\",1)\n",
    "\n",
    "#Define os tipos de dados das colunas\n",
    "df_resultados['Classificador'] = df_resultados['Classificador'].astype(str)\n",
    "df_resultados['Método'] = df_resultados['Método'].astype(str)\n",
    "df_resultados['Atributo'] = df_resultados['Atributo'].astype(str)\n",
    "df_resultados['Fold'] = df_resultados['Fold'].astype(int)\n",
    "df_resultados['Grupo'] = df_resultados['Grupo'].astype(str)\n",
    "df_resultados['Acurácia'] = df_resultados['Acurácia'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titulo_acc = df_resultados[(df_resultados['Atributo'] == 'Título') & (df_resultados['Método'] == 'ACC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setBoxColors(bp, cor):\n",
    "    for item in ['whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[item], color='black')\n",
    "    plt.setp(bp[\"boxes\"], facecolor=cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_box_plots(df, atributo, metodo):\n",
    "    \n",
    "    flierprops = dict(marker='*', markerfacecolor='black', markersize=10,\n",
    "                  markeredgecolor='none')\n",
    "    medianprops = dict(linestyle='-', linewidth=1.1)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    classificadores = ['MVS','NBM','RL']\n",
    "    posicoes = [[1,2,3,4,5],[8,9,10,11,12],[15,16,17,18,19]]\n",
    "    grupos_ruido = ['C','I','II','III','IV']\n",
    "    \n",
    "    for i in range(len(classificadores)):\n",
    "        lista_ruidos = []\n",
    "        for j in range(len(grupos_ruido)):\n",
    "            df_ruido = pd.DataFrame(df[(df['Grupo'] == grupos_ruido[j]) \n",
    "                                                          & (df['Classificador'] == classificadores[i])\n",
    "                                                          & (df['Atributo'] == atributo) \n",
    "                                                          & (df['Método'] == metodo)])\n",
    "            lista_ruidos.append(df_ruido['Acurácia'])\n",
    "        \n",
    "        bp = boxplot(lista_ruidos, positions=posicoes[i], patch_artist=True, flierprops=flierprops,\n",
    "                    medianprops=medianprops, showcaps=False, widths=0.6, labels=['C', 'I', 'II', 'III', 'IV'])\n",
    "        if i == 0:\n",
    "            setBoxColors(bp,'blue')\n",
    "        elif i == 1:\n",
    "            setBoxColors(bp,'orange')\n",
    "        elif i == 2:\n",
    "            setBoxColors(bp,'green')\n",
    "    \n",
    "    xlim(0,20)\n",
    "    ylim(25,65)\n",
    "    #ax.set_xticks([1.5, 4.5, 7.5])\n",
    "    ax.set_ylabel('Acurácia (%)')\n",
    "    ax.set_yticks([25,30,35,40,45,50,55,60,65])\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    secax = ax.secondary_xaxis(-0.08)\n",
    "    secax.xlim = (0,20)\n",
    "    secax.spines['bottom'].set_visible(False)\n",
    "    \n",
    "    secax.set_xticks([3,10,17])\n",
    "    \n",
    "    secax.set_xticklabels(classificadores)\n",
    "    secax.tick_params(axis='x', length=0)\n",
    "    \n",
    "    plt.yscale('linear')\n",
    "    \n",
    "    plt.title('Atributo {}'.format(atributo), y=1.05, pad=-10, loc='right')\n",
    "    \n",
    "    plt.plot([], c='blue')\n",
    "    plt.plot([], c='orange')\n",
    "    plt.plot([], c='green')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cria_box_plots(df_resultados, 'Título', 'ACC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "atributos = ('Título', 'Resumo', 'Palavras-chave', 'Texto')\n",
    "\n",
    "for atributo in atributos:\n",
    "    cria_box_plots(df_resultados, atributo, 'ACC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = plt.axes()\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_ac[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_mvs = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_nbm = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_rl = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "bp = boxplot(lista_ruidos_titulo_acc_mvs, positions=[1,2,3,4,5], patch_artist=True)\n",
    "setBoxColors(bp,'blue')\n",
    "\n",
    "bp = boxplot(lista_ruidos_titulo_acc_nbm, positions=[6,7,8,9,10], patch_artist=True)\n",
    "setBoxColors(bp,'orange')\n",
    "\n",
    "\n",
    "bp = boxplot(lista_ruidos_titulo_acc_rl, positions=[11,12,13,14,15], patch_artist=True)\n",
    "setBoxColors(bp,'green')\n",
    "\n",
    "\n",
    "xlim(0,16)\n",
    "ylim(30,50)\n",
    "ax.set_xticklabels(['C', 'I', 'II', 'III', 'IV','C', 'I', 'II', 'III', 'IV','C', 'I', 'II', 'III', 'IV'])\n",
    "#ax.set_xticks([1.5, 4.5, 7.5])\n",
    "\n",
    "plt.plot([], c='blue', label='MVS')\n",
    "plt.plot([], c='orange', label='NBM')\n",
    "plt.plot([], c='green', label='RL')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc_acc = df_resultados[(df_resultados['Atributo'] == 'Palavras-chave') & (df_resultados['Método'] == 'ACC')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "ax = plt.axes()\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'MVS')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_mvs = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'NBM')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_nbm = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "df_ruidoC = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'C') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoI = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'I') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'II') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoIII = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'III') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "df_ruidoIV = pd.DataFrame(df_titulo_acc[(df_titulo_acc['Grupo'] == 'IV') & (df_titulo_acc['Classificador'] == 'RL')], columns=['Acurácia'])\n",
    "\n",
    "lista_ruidos_titulo_acc_rl = [df_ruidoC['Acurácia'], df_ruidoI['Acurácia'], df_ruidoII['Acurácia'], df_ruidoIII['Acurácia'],\n",
    "               df_ruidoIV['Acurácia']]\n",
    "\n",
    "\n",
    "bp = boxplot(lista_ruidos_acc_mvs, positions=[1,2,3,4,5], patch_artist=True)\n",
    "setBoxColors(bp,'blue')\n",
    "\n",
    "bp = boxplot(lista_ruidos_acc_nbm, positions=[6,7,8,9,10], patch_artist=True)\n",
    "setBoxColors(bp,'orange')\n",
    "\n",
    "\n",
    "bp = boxplot(lista_ruidos_acc_rl, positions=[11,12,13,14,15], patch_artist=True)\n",
    "setBoxColors(bp,'green')\n",
    "\n",
    "\n",
    "xlim(0,16)\n",
    "ylim(20,70)\n",
    "ax.set_xticklabels(['C', 'I', 'II', 'III', 'IV','C', 'I', 'II', 'III', 'IV','C', 'I', 'II', 'III', 'IV'])\n",
    "#ax.set_xticks([1.5, 4.5, 7.5])\n",
    "\n",
    "plt.plot([], c='blue', label='MVS')\n",
    "plt.plot([], c='orange', label='NBM')\n",
    "plt.plot([], c='green', label='RL')\n",
    "plt.legend()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
