{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07be0c8f",
   "metadata": {},
   "source": [
    "# Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10d533ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "import unidecode\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from numpy import mean\n",
    "from nltk import tokenize\n",
    "from string import punctuation\n",
    "from string import ascii_letters\n",
    "from nltk.stem import RSLPStemmer\n",
    "from sklearn import metrics\n",
    "from pandas_ods_reader import read_ods\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from pylab import plot, show, savefig, xlim, figure, ylim, legend, boxplot, setp, axes\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7638f1",
   "metadata": {},
   "source": [
    "# Funções"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cdf695a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função para ler os dados e realizar algumas definições\n",
    "#Entrada: Nenhuma\n",
    "#Saída: Dataframe com os dados e os tipos atribuídos\n",
    "\n",
    "def leitura_e_configuracao():\n",
    "    df = read_ods(\"base-de-dados-cientificos.ods\",1)\n",
    "\n",
    "    #Define os tipos de dados das colunas\n",
    "    df['Palavras-chave'] = df['Palavras-chave'].astype(str)\n",
    "    df['Título'] = df['Título'].astype(str)\n",
    "    df['Resumo'] = df['Resumo'].astype(str)\n",
    "    df['Categoria'] = df['Categoria'].astype(str)\n",
    "    df['ID'] = df['ID'].astype(int)\n",
    "    \n",
    "    # atribuição dos ids a cada uma das categorias\n",
    "    for abstract in df:\n",
    "        df.loc[df['Categoria'] == 'Ciências Agrárias', 'ID_Categoria'] = 0\n",
    "        df.loc[df['Categoria'] == 'Ciências Biológicas', 'ID_Categoria'] = 1\n",
    "        df.loc[df['Categoria'] == 'Ciências Exatas e da Terra', 'ID_Categoria'] = 2\n",
    "        df.loc[df['Categoria'] == 'Ciências Humanas', 'ID_Categoria'] = 3\n",
    "        df.loc[df['Categoria'] == 'Ciências Sociais Aplicadas', 'ID_Categoria'] = 4\n",
    "        df.loc[df['Categoria'] == 'Ciências da Saúde', 'ID_Categoria'] = 5\n",
    "        df.loc[df['Categoria'] == 'Engenharias', 'ID_Categoria'] = 6\n",
    "        df.loc[df['Categoria'] == 'Lingüística, Letras e Artes', 'ID_Categoria'] = 7\n",
    "        df.loc[df['Categoria'] == 'Multidisciplinar', 'ID_Categoria'] = 8\n",
    "    \n",
    "    df['ID_Categoria'] = df['ID_Categoria'].astype(int) #tipo de dado da nova coluna criada\n",
    "    df['Texto'] = df['Título'] + df['Resumo'] + df['Palavras-chave'] # Atributo texto é a união do título, resumo\n",
    "                                                                     # e palavras-chave\n",
    "    \n",
    "    return df # retorna o dataframe\n",
    "    \n",
    "#Função para realizar o pré-processamento dos dados\n",
    "#Entrada: Dataframe com os dados e o atributo a ser pré-processado\n",
    "#Saída: Nenhuma\n",
    "\n",
    "def pre_processamento(df, atributo):\n",
    "    \n",
    "    #letras minúsculas\n",
    "    df[atributo] = [texto.lower() for texto in df[atributo]]\n",
    "\n",
    "    #remoção de acentos\n",
    "    df[atributo] = [unidecode.unidecode(texto) for texto in df[atributo]]\n",
    "\n",
    "    #remoção de stop words\n",
    "    stop_words = nltk.corpus.stopwords.words('portuguese')\n",
    "    stop_words.extend(['artigo','sobre', 'resultado','objetivo','estudo','brasil', 'trabalho', \n",
    "                      'delineamento', 'experimental','analise'])\n",
    "    lista_stopwords = []\n",
    "    for abstract in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(abstract)\n",
    "        novo_texto = ' '.join([token for token in tokens if token not in stop_words])\n",
    "        lista_stopwords.append(novo_texto)\n",
    "    df[atributo] = lista_stopwords\n",
    "\n",
    "    #remoção de pontuação\n",
    "    pontuacoes = list(punctuation)\n",
    "    pontuacao = []\n",
    "    for texto in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(texto)\n",
    "        novo_texto = ' '.join([token for token in tokens if token not in pontuacoes])\n",
    "        pontuacao.append(novo_texto)\n",
    "    df[atributo] = pontuacao\n",
    "\n",
    "    #Retira textos não desejados\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'[0-9]','',x))\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'[/(){}\\[\\]\\#\\|@,;.:-]',' ',x))\n",
    "    df[atributo] = df[atributo].apply(lambda x: re.sub(r'\\d+', '', x))\n",
    "\n",
    "    #obtenção da raíz das palavras\n",
    "    stemmer = RSLPStemmer()\n",
    "    raizes = []\n",
    "    for texto in df[atributo]:\n",
    "        tokens = tokenize.WhitespaceTokenizer().tokenize(texto)\n",
    "        novo_texto = ' '.join([stemmer.stem(token) for token in tokens])\n",
    "        raizes.append(novo_texto)\n",
    "    df[atributo] = raizes\n",
    "    \n",
    "#Função para realizar a extração de características\n",
    "#Entrada: Dataframe e o atributo correspondente\n",
    "#Saída vetor de características e os rótulos das categorias\n",
    "    \n",
    "def extracao_caracteristicas(df, atributo):\n",
    "    tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', ngram_range=(1, 2)) # aplicação do TF-IDF para\n",
    "                                                                                        # extração de características\n",
    "    vetor_caracteristicas = tfidf.fit_transform(df[atributo]).toarray() # obtenção do vetor de características\n",
    "    rotulos = df.ID_Categoria\n",
    "    return vetor_caracteristicas, rotulos\n",
    "\n",
    "#Função para realizar a seleção de características\n",
    "#Entrada: vetor de características e os rótulos das categorias\n",
    "#Saída: vetor de características atualizado\n",
    "\n",
    "def selecao_caracteristicas(vetor_caracteristicas, rotulos):\n",
    "    chi2_test = SelectKBest(chi2,k=int((vetor_caracteristicas.shape[1]/2))) #Teste Qui-Quadrado usando para\n",
    "                                                                            #selecionar metade das amostras\n",
    "    vetor_caracteristicas = chi2_test.fit_transform(vetor_caracteristicas,rotulos) # obtenção do vetor de características\n",
    "    return vetor_caracteristicas\n",
    "\n",
    "#Função para realizar a validação do modelo usando 10-fold cross validation\n",
    "#Entrada: Dataframe, classificador, vetor de características e os rótulos das categorias\n",
    "#Saída: Dataframe com o resultado dos 10 folds\n",
    "\n",
    "def validacao(df, modelo, vetor_caracteristicas, rotulos):\n",
    "    \n",
    "    vc_df = pd.DataFrame(index=range(10))\n",
    "    entradas = []\n",
    "    acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "    for num_fold, acuracia in enumerate(acuracias):\n",
    "        entradas.append((num_fold, acuracia))\n",
    "    vc_df = pd.DataFrame(entradas, columns=['num_fold', 'acuracia'])\n",
    "    \n",
    "    return vc_df\n",
    "\n",
    "#Função para avaliar as dimensões de qualidade segundo os métodos de contaminação utilizando 10-fold cross validation\n",
    "#e as condições experimentais de ruído\n",
    "#Entrada: dimensão de qualidade a ser avaliada, atributo alvo, algoritmo de classificação selecionado\n",
    "#Saída: lista contendo uma lista de 10 folds para cada condição experimental avaliada\n",
    "\n",
    "def avaliacao_DQ(dimensao, atributo, classificador):\n",
    "    ruidos = [0, 10, 20, 30, 40] # Grupo Controle, Grupo I, Grupo II, Grupo III, Grupo IV\n",
    "    folds = []\n",
    "    for ruido in ruidos:\n",
    "        df = leitura_e_configuracao() # leitura/configuração do dataframe\n",
    "        #contaminação\n",
    "        if(dimensao == 'Acurácia-add'):\n",
    "            contamina_acuracia(df, atributo, 'adicao', ruido)\n",
    "        elif(dimensao == 'Acurácia-rm'):\n",
    "            contamina_acuracia(df, atributo, 'remocao', ruido)\n",
    "        elif(dimensao == 'Acurácia-subs'):\n",
    "            contamina_acuracia(df, atributo, 'substituicao', ruido)\n",
    "        elif(dimensao == 'Completude'):\n",
    "            contamina_completude(df, atributo, ruido)\n",
    "        elif(dimensao == 'Consistência'):\n",
    "            contamina_consistencia(df, atributo, ruido)\n",
    "        pre_processamento(df, atributo) # pré-processamento após a contaminação\n",
    "        vetor_caracteristicas, rotulos = extracao_caracteristicas(df, atributo) #extração de características\n",
    "        vetor_caracteristicas = selecao_caracteristicas(vetor_caracteristicas, rotulos)#seleção de características\n",
    "        vc_df = validacao(df, classificador, vetor_caracteristicas, rotulos)#validação do modelo\n",
    "        folds.append(vc_df.acuracia.values) # adiciona os 10 folds do grupo ruído à lista de folds\n",
    "        \n",
    "    return folds\n",
    "\n",
    "#Função para gerar uma lista de valores em ASCII a partir de uma string\n",
    "#Entrada: string desejada\n",
    "#Saída: lista com os caracteres em ASCII\n",
    "\n",
    "def gera_lista_valores(string):\n",
    "    lista_valores = []\n",
    "    lista_carac = []\n",
    "    i = 0\n",
    "    for i in range(len(string)):\n",
    "        lista_carac.append(string[i])\n",
    "    return [int(ord(carac)) for carac in lista_carac]\n",
    "\n",
    "#Função para calcular a média de uma lista de valores\n",
    "#Entrada: lista de valores\n",
    "#Saída: média dos valores da lista\n",
    "\n",
    "def calcula_media(lista_valores):\n",
    "    soma = 0\n",
    "    media = 0\n",
    "    for valor in lista_valores:\n",
    "        soma += valor\n",
    "    return soma / len(lista_valores)\n",
    "\n",
    "#Função para o cálculo do desvio padrão de uma lista de valores\n",
    "#Entrada: média dos valores da lista e a lista de valores\n",
    "#Saída: desvio padrão da lista de valores\n",
    "\n",
    "def calcula_desvio(lista_valores, media):\n",
    "    desvio = 0\n",
    "    for valor in lista_valores:\n",
    "        desvio += (valor - media)**2\n",
    "    return (desvio / len(lista_valores))**(1/2)\n",
    "\n",
    "#Função para obter a probabilidade de um caracter ser contaminado segundo uma distribuição de probabilidade\n",
    "#Entrada: média e desvio padrão dos valores em ASCII correspondentes ao artigo e valor do caracter em ASCII sendo\n",
    "#analisado\n",
    "#Saída: probabilidade do caracter ser contaminado\n",
    "\n",
    "def ruido_gaussiano(media, desvio, valor):\n",
    "    print((1 / (desvio * math.sqrt(2 * math.pi))) * math.exp(-(((valor - media) ** 2) / (2 * (desvio ** 2)))))\n",
    "    return (1 / (desvio * math.sqrt(2 * math.pi))) * math.exp(-(((valor - media) ** 2) / (2 * (desvio ** 2))))\n",
    "\n",
    "#Função para realizar a contaminação da dimensão de qualidade Acurácia\n",
    "#Entrada: dataframe, atributo escolhido, método(adição,remoção,substituição), porcentagem de ruído\n",
    "#Saída: dataframe modificado\n",
    "\n",
    "def contamina_acuracia(df, escolha_atributo, metodo, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    \n",
    "    if (porc_ruido == 0): # retorna caso não haja contaminação\n",
    "        return\n",
    "    \n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100)) # quantidade de artigos que serão contaminados\n",
    "    atributo_contaminado = escolha_atributo \n",
    "    i = 0\n",
    "    \n",
    "    while i < qtd_artigos: # laço para contaminar os artigos\n",
    "        \n",
    "        lista_carac = []\n",
    "        lista_valores = []\n",
    "        indice = random.choice(df.index) # artigo é selecionado de maneira aleatória\n",
    "        \n",
    "        if indice in lista_artigos: # verifica se o artigo já foi contaminado previamente\n",
    "            while indice in lista_artigos:\n",
    "                indice = random.choice(df.index)\n",
    "                \n",
    "        lista_valores = gera_lista_valores(df.loc[indice, atributo_contaminado]) # obtém os valores em ascii \n",
    "                                                                                 # em formato de lista\n",
    "        media = calcula_media(lista_valores) # cálculo da média dos valores em ascii\n",
    "        desvio = calcula_desvio(lista_valores, media) # desvio padrão dos valores em ascii\n",
    "        \n",
    "        for valor in lista_valores: # percorre os caracteres em ascii\n",
    "            \n",
    "            if ((ra) \n",
    "                and (chr(valor).isalpha())): # se o caracter for contaminado\n",
    "                \n",
    "                caracter = random.choice(ascii_letters) # obtém um caracter aleatório\n",
    "                \n",
    "                if(not caracter.isalpha()): # gera novo caracter enquanto este não for alfabético\n",
    "                    while(not caracter.isalpha()):\n",
    "                        caracter = random.choice(ascii_letters)\n",
    "                                \n",
    "                if(metodo == 'substituicao'): # método de substituição de caracteres\n",
    "                    lista_carac.append(caracter) # adiciona o caracter aleatório no lugar do antigo na nova lista\n",
    "                elif(metodo == 'adicao'): # método de adição de caracteres\n",
    "                    lista_carac.extend([chr(valor), caracter]) # adiciona o caracter antigo junto com o aleatório\n",
    "                                                               # à nova lista\n",
    "                elif(metodo == 'remocao'): # remoção de caracteres\n",
    "                    pass # caso o caracter seja contaminado, ele não é adicionado à lista de caracteres\n",
    "            \n",
    "            else: # caracter não será contaminado\n",
    "                lista_carac.append(chr(valor)) # troca o valor em ascii pelo caracter correspondente\n",
    "                                               # e o adiciona à lista\n",
    "                \n",
    "        df.loc[indice, atributo_contaminado] = ''.join([carac for carac in lista_carac]) # substitui o artigo pela\n",
    "                                                                                         # lista resultante\n",
    "        lista_artigos.append(indice) # adiciona o índice do artigo à lista de artigos contaminados\n",
    "        i+=1\n",
    "\n",
    "#Função para realizar a contaminação da dimensão de qualidade Completude\n",
    "#Entrada: dataframe, atributo escolhido, porcentagem de ruído\n",
    "#Saída: dataframe modificado        \n",
    "\n",
    "def contamina_completude(df, escolha_atributo, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    #lista_atributos = ['Título', 'Resumo', 'Palavras-chave']\n",
    "    if(porc_ruido == 0):\n",
    "        return\n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100))\n",
    "    i = 0\n",
    "    atributo_contaminado = escolha_atributo\n",
    "    while i < qtd_artigos:\n",
    "        indice = random.choice(df.index) # sorteia um artigo aleatório\n",
    "        if indice in lista_artigos: # se o artigo já foi contaminado\n",
    "            while indice in lista_artigos: # procura por um novo artigo enquanto estiver na lista dos que já foram contaminados\n",
    "                indice = random.choice(df.index)\n",
    "        df[atributo_contaminado] = df[atributo_contaminado].replace([df[atributo_contaminado][indice]], '') # apaga o atributo\n",
    "        lista_artigos.append(indice) # adiciona o artigo contaminado à lista de artigos que já foram contaminados\n",
    "        i += 1\n",
    "\n",
    "#Função para realizar a contaminação da dimensão de qualidade Consistência\n",
    "#Entrada: dataframe, atributo escolhido, porcentagem de ruído\n",
    "#Saída: dataframe modificado         \n",
    "        \n",
    "def contamina_consistencia(df, escolha_atributo1, porc_ruido):\n",
    "    lista_artigos = []\n",
    "    lista_atributos = ['Título', 'Resumo', 'Palavras-chave']\n",
    "    if(porc_ruido == 0):\n",
    "        return\n",
    "    porc_ruido /= 2\n",
    "    qtd_artigos = int(df.shape[0] * (porc_ruido/100)) # número de artigos a serem contaminados\n",
    "    i = 0\n",
    "    atributo_contaminado1 = escolha_atributo1\n",
    "    atributo_contaminado2 = random.choice(lista_atributos)\n",
    "    while i < qtd_artigos:\n",
    "        indice1 = random.choice(df.index)\n",
    "        indice2 = random.choice(df.index)\n",
    "        if(df['ID_Categoria'][indice1] == df['ID_Categoria'][indice2]):\n",
    "                while(df['ID_Categoria'][indice1] == df['ID_Categoria'][indice2]):\n",
    "                        indice1 = random.choice(df.index)\n",
    "        \n",
    "        else:\n",
    "            temp = df[atributo_contaminado1][indice1]\n",
    "            if(atributo_contaminado2 == atributo_contaminado1):\n",
    "                while(atributo_contaminado2 == atributo_contaminado1):\n",
    "                    atributo_contaminado2 = random.choice(lista_atributos)\n",
    "            df[atributo_contaminado1] = df[atributo_contaminado1].replace([df[atributo_contaminado1][indice1]], [df[atributo_contaminado2][indice2]])\n",
    "            df[atributo_contaminado2] = df[atributo_contaminado2].replace([df[atributo_contaminado2][indice2]], temp)\n",
    "            i+=1\n",
    "            \n",
    "#Função para obter a melhor divisão do conjunto de treinamento/teste e exibir graficamente\n",
    "#Entrada: classificador\n",
    "#Saída: indicação gráfica da melhor porcentagem de amostras usadas para o treinamento do modelo de classificação\n",
    "            \n",
    "def melhor_divisao(modelo):\n",
    "    lista_acuracias = []\n",
    "    lista_porc = []\n",
    "    i = 0.01 # Começa em 1%\n",
    "    while i < 1: # Enquanto não chegar a 100%\n",
    "        X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=i, random_state=0)\n",
    "        modelo.fit(X_train, y_train) # faz o treinamento usando a porcentagem i como conjunto de treino\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        lista_acuracias.append(accuracy_score(y_test, y_pred)*100)\n",
    "        lista_porc.append(i*100)\n",
    "        i += 0.01\n",
    "    \n",
    "    #configuração do gráfico a ser exibido\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(lista_porc, lista_acuracias, 'black')\n",
    "    plt.xlabel('Conjunto de Treino (%)')\n",
    "    plt.ylabel('Acurácia (%)')\n",
    "    indice = lista_acuracias.index(max(lista_acuracias))\n",
    "    plt.scatter(lista_porc[indice], max(lista_acuracias), c='red', linewidths=2)\n",
    "    plt.axhline(y=max(lista_acuracias), xmax=lista_porc[indice]/105, linestyle='--', color=\"red\")\n",
    "    plt.axvline(x=lista_porc[indice], ymax=max(lista_acuracias)/(max(lista_acuracias)+5), linestyle='--', color=\"red\")\n",
    "    plt.text(lista_porc[indice]+2, max(lista_acuracias)+0.5, '({:.1f}, {:.1f})'.format(lista_porc[indice], max(lista_acuracias)))\n",
    "    plt.margins(0.1)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "#Função para gerar as curvas ROC e disponibilizá-las em formato gráfico\n",
    "#Entrada: classificador e melhor divisão do conjunto de treino\n",
    "#Saída: representação gráfica das curvas ROC para o modelo escolhido\n",
    "    \n",
    "def gera_curvas_roc(modelo, cjto_treino):\n",
    "\n",
    "    #treinamento do modelo utilizando o melhor split possível\n",
    "    X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=(cjto_treino/100), random_state=0)\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    pred_prob = modelo.predict_proba(X_test) #obtenção das probabilidades que serão utilizadas para construir as\n",
    "                                             #curvas ROC\n",
    "    \n",
    "    FPR = {} #dicionário contendo os pares chave-valor dos falsos positivos (1-Especificidade)\n",
    "    TPR = {} #dicionárito contendo os pares chave-valor dos verdadeiros positivos (Sensibilidade)\n",
    "    limite = {}\n",
    "\n",
    "    num_classes = 9\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        FPR[i], TPR[i], limite[i] = roc_curve(y_test, pred_prob[:, i], pos_label=i) #obtenção dsa curvas ROC\n",
    "                                                                                    #para as nove classes\n",
    "    \n",
    "    # plotando a área sob a curva e configurando exbição do gráfico\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(FPR[0], TPR[0], color='#e41a1c', linestyle='-', label='CA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[1], TPR[1], color='#377eb8', linestyle='-', label='CB vs Resto',linewidth=3)\n",
    "    plt.plot(FPR[2], TPR[2], color='#4daf4a', linestyle='-', label='CET vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[3], TPR[3], color='#984ea3', linestyle='-', label='CH vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[4], TPR[4], color='#ff7f00', linestyle='-', label='CSA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[5], TPR[5], color='#ffff33', linestyle='-', label='CS vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[6], TPR[6], color='#a65628', linestyle='-', label='E vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[7], TPR[7], color='#f781bf', linestyle='-', label='LLA vs Resto', linewidth=3)\n",
    "    plt.plot(FPR[8], TPR[8], color='#999999', linestyle='-', label='M vs Resto', linewidth=3)\n",
    "    plt.xlabel('Taxa de Falsos Positivos (1 - Especificidade)', weight='book')\n",
    "    plt.ylabel('Taxa de Verdadeiros Positivos (Sensibilidade)', weight='book')\n",
    "    ax.xaxis.set_tick_params(width=2)\n",
    "    ax.yaxis.set_tick_params(width=2)\n",
    "    leg = plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=26, shadow=True,\n",
    "                     fancybox=True)\n",
    "    leg.get_frame().set_linewidth(3)\n",
    "    for i in range(num_classes):\n",
    "        leg.get_lines()[i].set_linewidth(5)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    plt.setp(ax.spines.values(), linewidth=2)\n",
    "    fig.set_size_inches(20, 10)\n",
    "    plt.show()\n",
    "    \n",
    "#Função para criar o box-plot contendo os dados dos 10 folds obtidos por meio do 10-fold cross validation para cada\n",
    "#um dos algoritmos\n",
    "#Entrada: valores do eixo x, valores do eixo y e fonte dos dados\n",
    "#Saída: Representação gráfica do box-plot\n",
    "    \n",
    "def cria_box_plot(eixo_x, eixo_y):\n",
    "\n",
    "    #configuração do gráfico\n",
    "    fig, ax = plt.subplots()\n",
    "    flierprops = dict(marker='*', markerfacecolor='black', markersize=8,\n",
    "                  markeredgecolor='none')\n",
    "    medianprops = dict(linestyle='-', linewidth=1.1)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    \n",
    "    #modelos a serem validados\n",
    "    modelos = [\n",
    "    LinearSVC(random_state=0),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0, solver='liblinear')\n",
    "]\n",
    "    \n",
    "    vc_df = pd.DataFrame(index=range(10 * len(modelos))) #dataframe para os folds da validação cruzada\n",
    "\n",
    "    entradas = []\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    for modelo in modelos:\n",
    "        nome_modelo = modelo.__class__.__name__\n",
    "        if(nome_modelo == \"LinearSVC\"):\n",
    "            nome_modelo = \"MVS\"\n",
    "        elif(nome_modelo == \"MultinomialNB\"):\n",
    "            nome_modelo = \"NB\"\n",
    "        elif(nome_modelo == \"LogisticRegression\"):\n",
    "            nome_modelo = \"RL\"\n",
    "        acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "        for num_fold, acuracia in enumerate(acuracias):\n",
    "            entradas.append((nome_modelo, num_fold, acuracia))\n",
    "    \n",
    "    #Adequação do dataframe\n",
    "    vc_df = pd.DataFrame(entradas, columns=['Classificador', 'Num_Fold', 'Acurácia (%)'])\n",
    "    vc_df['Acurácia (%)'] = [acuracia * 100 for acuracia in vc_df['Acurácia (%)']]\n",
    "\n",
    "    #Construção do boxplot\n",
    "    sns.boxplot(x=eixo_x, y=eixo_y, palette='bright', data=vc_df, orient='v', width=0.3,\n",
    "           saturation=1, linewidth=1, showcaps=False, flierprops=flierprops, medianprops=medianprops)\n",
    "    plt.show()\n",
    "    \n",
    "    return vc_df\n",
    "    \n",
    "    \n",
    "#Função para realizar a leitura e configuração dos resultados dos folds\n",
    "    \n",
    "def leitura_e_configuracao_resultados():\n",
    "\n",
    "    df_resultados = read_ods(\"resultadosFoldsFormatado.ods\",1)\n",
    "\n",
    "    #Define os tipos de dados das colunas\n",
    "    df_resultados['Classificador'] = df_resultados['Classificador'].astype(str)\n",
    "    df_resultados['Método'] = df_resultados['Método'].astype(str)\n",
    "    df_resultados['Atributo'] = df_resultados['Atributo'].astype(str)\n",
    "    df_resultados['Fold'] = df_resultados['Fold'].astype(int)\n",
    "    df_resultados['Grupo'] = df_resultados['Grupo'].astype(str)\n",
    "    df_resultados['Acurácia'] = df_resultados['Acurácia'].astype(float)\n",
    "    \n",
    "    return df_resultados\n",
    "    \n",
    "#Função para definir cores do Box-plot    \n",
    "\n",
    "def setCorBoxPlot(bp, cor):\n",
    "    for item in ['whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[item], color='black')\n",
    "    plt.setp(bp[\"boxes\"], facecolor=cor)\n",
    "\n",
    "#Função para criar os box-plots para os algoritmos sob as condições experimentais de ruído e um método de contaminação\n",
    "#Entrada: dataframe, atributo contaminado, método de contaminação, eixo do gráfico construído\n",
    "#Saída: gráfico com quatro quadrantes, onde cada um contém os box-plots dos classificadores\n",
    "#e representam o atributo contaminado segundo as condições experimentais de ruído\n",
    "\n",
    "def cria_box_plots(df, atributo, metodo, ax):\n",
    "    \n",
    "    #configurações do box-plot\n",
    "    flierprops = dict(marker='*', markerfacecolor='black', markersize=10,\n",
    "                  markeredgecolor='none')\n",
    "    medianprops = dict(linestyle='-', linewidth=1.1)\n",
    "    \n",
    "    classificadores = ['MVS','NBM','RL'] #classificadores\n",
    "    posicoes = [[1,2,3,4,5],[8,9,10,11,12],[15,16,17,18,19]] #posições dos box-plots\n",
    "    grupos_ruido = ['C','I','II','III','IV'] #condições experimentais\n",
    "    \n",
    "    for i in range(len(classificadores)): # para cada classificador\n",
    "        \n",
    "        lista_ruidos = []\n",
    "        for j in range(len(grupos_ruido)):\n",
    "            #filtra o dataframe com as colunas desejadas\n",
    "            df_ruido = pd.DataFrame(df[(df['Grupo'] == grupos_ruido[j]) \n",
    "                                                          & (df['Classificador'] == classificadores[i])\n",
    "                                                          & (df['Atributo'] == atributo) \n",
    "                                                          & (df['Método'] == metodo)])\n",
    "            lista_ruidos.append(df_ruido['Acurácia']) #inclui apenas os valores de acurácia na lista\n",
    "        \n",
    "        bp = ax.boxplot(lista_ruidos, positions=posicoes[i], patch_artist=True, flierprops=flierprops,\n",
    "                    medianprops=medianprops, showcaps=False, labels=grupos_ruido) #constroi o box-plot do classificador\n",
    "        #define as cores\n",
    "        if i == 0:\n",
    "            setCorBoxPlot(bp,'blue')\n",
    "        elif i == 1:\n",
    "            setCorBoxPlot(bp,'orange')\n",
    "        elif i == 2:\n",
    "            setCorBoxPlot(bp,'green')\n",
    "\n",
    "    #configurações dos eixos\n",
    "    ax.set_yticks([20,30,40,50,60,70])\n",
    "    ax.set_xlim(0,20)\n",
    "    ax.set_ylim(19,72)\n",
    "    \n",
    "    #adição do rótulo correspondente ao classificador utilizado no eixo x\n",
    "    secax = ax.secondary_xaxis(-0.08)\n",
    "    secax.xlim = (0,20)\n",
    "    secax.spines['bottom'].set_visible(False)\n",
    "    secax.set_xticks([3,10,17])\n",
    "    secax.set_xticklabels(classificadores)\n",
    "    secax.tick_params(axis='x', length=0)\n",
    "    \n",
    "    #adição do titulo ao subplot indicando o atributo correspondente\n",
    "    ax.set_title('{}'.format(atributo), y=0.9, pad=-10, loc='right', position=(0.97, 0.5))\n",
    "    \n",
    "    #configurações do texto do gráfico\n",
    "    font = {'family':'sans-serif',\n",
    "            'weight':'book',\n",
    "            'size': 16}\n",
    "    \n",
    "    plt.rc('font', **font)\n",
    "\n",
    "#Função para criar o grid e os 4 quadrantes onde serão colocados os box-plots\n",
    "#Saída: os axis representando cada um dos quadrantes\n",
    "\n",
    "def set_grid(metodo):\n",
    "    fig = plt.figure(figsize=(20,10)) #criação da figura\n",
    "    plt.ylabel(\"Acurácia (%)\", labelpad=40) #título eixo y\n",
    "    #omissão dos ticks dos eixos para não sobressair\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    gs = fig.add_gridspec(2, 2, hspace=0, wspace=0) #especificações do grid\n",
    "    (ax1, ax2), (ax3, ax4) = gs.subplots(sharex='col', sharey='row') #compartilhamento das linhas e colunas\n",
    "    \n",
    "    return ax1,ax2,ax3,ax4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134a17f",
   "metadata": {},
   "source": [
    "# Testes-Contaminação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ba18db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Acurácia-add ✔\n",
      "\n",
      "Título: Completude ✔\n",
      "\n",
      "Título: Consistência ✔\n",
      "\n",
      "CPU times: user 6min 48s, sys: 1min 58s, total: 8min 47s\n",
      "Wall time: 5min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "atributo = 'Título'\n",
    "metodos = ['Acurácia-add', 'Completude', 'Consistência']\n",
    "modelo = LogisticRegression(random_state=0, solver='liblinear')\n",
    "\n",
    "for metodo in metodos:\n",
    "    lista_folds = []\n",
    "    i=0\n",
    "    arquivo = open(\"resultados/rl/acc/{}-{}-ACC.txt\".format(atributo, metodo),\"w\")\n",
    "    arquivo_folds = open(\"resultados/rl/folds/{}-{}-FOLDS.txt\".format(atributo, metodo),\"w\")\n",
    "    for i in range(10):\n",
    "        folds = avaliacao_DQ(metodo, atributo, modelo)\n",
    "        lista_folds.append(folds)\n",
    "    lista_media_folds = [sum(val)/10 for val in zip(*lista_folds)]\n",
    "    for media_fold in lista_media_folds:\n",
    "        arquivo.write(\"{}\\n\".format((sum(media_fold)/len(media_fold))*100))\n",
    "        for fold in media_fold:\n",
    "            arquivo_folds.write(\"{}\\n\".format(fold*100))\n",
    "    print(\"{}: {} ✔\\n\".format(atributo, metodo))\n",
    "    arquivo.close()\n",
    "    arquivo_folds.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f65bb",
   "metadata": {},
   "source": [
    "# Pré-processamento/Extração/Seleção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edef8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = leitura_e_configuracao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f016f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre_processamento(df, 'Texto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058eb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_caracteristicas, rotulos = extracao_caracteristicas(df, 'Texto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30021e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetor_caracteristicas = selecao_caracteristicas(vetor_caracteristicas, rotulos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dd0c7",
   "metadata": {},
   "source": [
    "## Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "73c172db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = leitura_e_configuracao()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0bdd4953",
   "metadata": {},
   "outputs": [],
   "source": [
    "artigo = df_teste.sample(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "df4ae354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016744287105261643\n",
      "0.01682800195398392\n",
      "0.013710048811204073\n",
      "0.01293148111242553\n",
      "0.016318837603451555\n",
      "0.015649199602325213\n",
      "0.016318837603451555\n",
      "0.010393384920965096\n",
      "0.016861511792332712\n",
      "0.015082069267329344\n",
      "0.01293148111242553\n",
      "0.01682800195398392\n",
      "0.00031036533874857905\n",
      "0.015082069267329344\n",
      "0.016318837603451555\n",
      "0.01293148111242553\n",
      "0.013710048811204073\n",
      "0.01476642588893438\n",
      "0.016631093655174265\n",
      "0.01682800195398392\n",
      "0.015082069267329344\n",
      "0.016861511792332712\n",
      "0.016881789647332248\n",
      "0.01476642588893438\n",
      "0.001148716376369452\n",
      "0.00031036533874857905\n",
      "0.015649199602325213\n",
      "0.01682800195398392\n",
      "0.016631093655174265\n",
      "0.012525150780582953\n",
      "0.015376819306708726\n",
      "0.016318837603451555\n",
      "0.015082069267329344\n",
      "0.01476642588893438\n",
      "0.01332703738235297\n",
      "0.016861511792332712\n",
      "0.001148716376369452\n",
      "0.00031036533874857905\n",
      "0.01332703738235297\n",
      "0.016318837603451555\n",
      "0.015376819306708726\n",
      "0.016898589761187372\n",
      "0.016318837603451555\n",
      "0.01476642588893438\n",
      "0.01332703738235297\n",
      "0.01682800195398392\n",
      "0.001148716376369452\n",
      "0.00031036533874857905\n",
      "0.01332703738235297\n",
      "0.012525150780582953\n",
      "0.01332703738235297\n",
      "0.01293148111242553\n",
      "0.01682800195398392\n",
      "0.015082069267329344\n",
      "0.01293148111242553\n",
      "0.016861511792332712\n",
      "0.016898589761187372\n",
      "0.016318837603451555\n",
      "0.015649199602325213\n",
      "0.016318837603451555\n",
      "0.016881789647332248\n",
      "0.016861511792332712\n",
      "0.016881789647332248\n",
      "0.01682800195398392\n",
      "0.0013932101335264978\n"
     ]
    }
   ],
   "source": [
    "contamina_acuracia(artigo, 'Palavras-chave', 'adicao', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "8190935f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ahmFiJnkoOáAcYitdDoVsw; dKeasmseeDdDexnLtFazçMãTod; fKiBtJaLsHel; mgiynQekrgaeidsb oirIgpâIneipcloMsX'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo['Palavras-chave'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab5f1ab",
   "metadata": {},
   "source": [
    "# Validação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f9e8a",
   "metadata": {},
   "source": [
    "## Validação cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38983332",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vc_df = cria_box_plot('Classificador', 'Acurácia (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "vc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2a4a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vc_df['Acurácia'] = vc_df['Acurácia (%)']\n",
    "acuracias = vc_df.groupby('Classificador').Acurácia.mean()\n",
    "acuracias.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9099d0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acuracias_desvios = vc_df.groupby('Classificador').Acurácia.std()\n",
    "acuracias_desvios.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ca6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "modelo = MultinomialNB()\n",
    "acuracias = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=10)\n",
    "print(mean(acuracias)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80a6c43",
   "metadata": {},
   "source": [
    "## Leave-one-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd87686",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loo = LeaveOneOut()\n",
    "modelo = LogisticRegression(random_state=0, solver='liblinear')\n",
    "acuracia = cross_val_score(modelo, vetor_caracteristicas, rotulos, scoring='accuracy', cv=loo)\n",
    "print(mean(acuracia)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e6d22",
   "metadata": {},
   "source": [
    "## Divisão treino/teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b634eaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melhor_divisao(LinearSVC(random_state=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633bd081",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=0.63, random_state=0)\n",
    "modelo = LinearSVC()\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8559d7",
   "metadata": {},
   "source": [
    "## Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454b105e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelo = SVC(kernel=\"linear\", probability=True)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(vetor_caracteristicas, rotulos, train_size=0.63, random_state=0)\n",
    "modelo.fit(X_train, y_train)\n",
    "y_pred = modelo.predict(X_test)\n",
    "\n",
    "#criação de dicionário (categoria,id)\n",
    "category_id_df = df[['Categoria', 'ID_Categoria']].drop_duplicates().sort_values('ID_Categoria')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "#criação de dicionário (id, categoria)\n",
    "id_to_category = dict(category_id_df[['ID_Categoria', 'Categoria']].values)\n",
    "\n",
    "#criação das siglas\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Agrárias', 'Categoria'] = 'CA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Biológicas', 'Categoria'] = 'CB'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Exatas e da Terra', 'Categoria'] = 'CET'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Humanas', 'Categoria'] = 'CH'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências Sociais Aplicadas', 'Categoria'] = 'CSA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Ciências da Saúde', 'Categoria'] = 'CS'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Engenharias', 'Categoria'] = 'E'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Lingüística, Letras e Artes', 'Categoria'] = 'LLA'\n",
    "category_id_df.loc[category_id_df['Categoria'] == 'Multidisciplinar', 'Categoria'] = 'M'\n",
    "\n",
    "#matriz de confusão\n",
    "conf_mat = confusion_matrix(y_test, y_pred)\n",
    "conf_mat.diagonal()/conf_mat.sum(axis=0)\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(conf_mat, annot=True, fmt='d',\n",
    "xticklabels=category_id_df.Categoria.values, yticklabels=category_id_df.Categoria.values)\n",
    "plt.ylabel('Real')\n",
    "plt.xlabel('Previsto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6e7ddc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imprime as métricas\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=df['Categoria'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faef97d",
   "metadata": {},
   "source": [
    "## Curvas-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ba07bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "modelo_calibrado = CalibratedClassifierCV(LinearSVC(random_state=0), cv=10, ensemble=False)\n",
    "\n",
    "gera_curvas_roc(modelo_calibrado, 63)\n",
    "gera_curvas_roc(MultinomialNB(), 82)\n",
    "gera_curvas_roc(LogisticRegression(random_state=0, solver='liblinear'), 82)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044ef2c",
   "metadata": {},
   "source": [
    "## Box-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c50eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = leitura_e_configuracao_resultados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039e125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax1,ax2,ax3,ax4 = set_grid('Acurácia')\n",
    "\n",
    "cria_box_plots(df_resultados, 'Título', 'ACC', ax1)\n",
    "cria_box_plots(df_resultados, 'Resumo', 'ACC', ax2)\n",
    "cria_box_plots(df_resultados, 'Palavras-chave', 'ACC', ax3)\n",
    "cria_box_plots(df_resultados, 'Texto', 'ACC', ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6808fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1,ax2,ax3,ax4 = set_grid('Completude')\n",
    "\n",
    "cria_box_plots(df_resultados, 'Título', 'COMP', ax1)\n",
    "cria_box_plots(df_resultados, 'Resumo', 'COMP', ax2)\n",
    "cria_box_plots(df_resultados, 'Palavras-chave', 'COMP', ax3)\n",
    "cria_box_plots(df_resultados, 'Texto', 'COMP', ax4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b6d4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1,ax2,ax3,ax4 = set_grid('Consistência')\n",
    "\n",
    "cria_box_plots(df_resultados, 'Título', 'CONS', ax1)\n",
    "cria_box_plots(df_resultados, 'Resumo', 'CONS', ax2)\n",
    "cria_box_plots(df_resultados, 'Palavras-chave', 'CONS', ax3)\n",
    "cria_box_plots(df_resultados, 'Texto', 'CONS', ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d64a52f",
   "metadata": {},
   "source": [
    "## Two-Way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7126ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296679a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados = leitura_e_configuracao_resultados()\n",
    "df_resultados = df_resultados.drop(columns='unnamed.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee3fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_way_anova(df, metodo, atributo):\n",
    "    \n",
    "    df_anova = pd.DataFrame(df[(df['Atributo'] == atributo) & (df['Método'] == metodo)])\n",
    "    \n",
    "    aov = pg.anova(dv='Acurácia', between=['Classificador', 'Grupo'], data=df_anova,\n",
    "             detailed=True)\n",
    "    \n",
    "    return df_anova, aov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5887fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def media_anova(df):\n",
    "    \n",
    "    grupos = ['C','I','II','III','IV']\n",
    "    lista_media_grupos = []\n",
    "    \n",
    "    for grupo in grupos:\n",
    "        df_grupo = pd.DataFrame(df[(df['Grupo'] == grupo)])\n",
    "        lista_media_grupos.append(df_grupo['Acurácia'].mean())\n",
    "    \n",
    "    return lista_media_grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7c9f47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "atributos = ['Título', 'Resumo','Palavras-chave','Texto']\n",
    "metodos = ['ACC', 'COMP', 'CONS']\n",
    "\n",
    "for metodo in metodos:\n",
    "    print('\\n{}\\n'.format(metodo))\n",
    "    for atributo in atributos:\n",
    "        \n",
    "        df_anova, anova = two_way_anova(df_resultados,metodo,atributo)\n",
    "        lista_medias = media_anova(df_anova)\n",
    "        \n",
    "        total = np.array([['Total',sum(anova['SS'].values), sum(anova['DF'].values)]])\n",
    "        total_anova = pd.DataFrame(data=total, columns=['Source','SS', 'DF'])\n",
    "        anova = anova.append(total_anova)\n",
    "        \n",
    "        display('{}'.format(atributo), anova)\n",
    "        print(\"Médias: {}\".format(lista_medias))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd24911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
